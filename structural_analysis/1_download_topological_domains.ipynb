{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to parse topological domains\n",
    "def parse_uniprot_topological_domains(int_protein_id):\n",
    "    # create uniprot url\n",
    "    uniprot_url = \"https://www.uniprot.org/uniprot/\" + int_protein_id + \".json\"\n",
    "    # read json data as a list\n",
    "    uniprot_data = json.loads(requests.get(uniprot_url).text)\n",
    "    # if there is no \"features\" field in the dictionary, return None\n",
    "    if not 'features' in uniprot_data:\n",
    "        print(\"No features for \" + int_protein_id)\n",
    "        return None\n",
    "    feature_list = uniprot_data['features']\n",
    "    # get the elements of the list in which the \"type\" field of the dictionary is \"topological domain\"\n",
    "    topo_domain_list = [x for x in feature_list if x['type'] == \"Topological domain\"]\n",
    "    # if the topo_domain_list is empty\n",
    "    if not topo_domain_list:\n",
    "        return None\n",
    "    # report the number of elements in the list\n",
    "    parsed_df = pd.DataFrame(columns=['uniprot_id', 'description', 'start', 'end'])\n",
    "    # for every element in the list, retrieve the 'description' field of the dictionary, the 'location','start','value and the 'location','end','value'\n",
    "    for i in range(len(topo_domain_list)):\n",
    "        description = topo_domain_list[i]['description']\n",
    "        start = topo_domain_list[i]['location']['start']['value']\n",
    "        end = topo_domain_list[i]['location']['end']['value']\n",
    "        parsed_df = pd.concat([parsed_df, pd.DataFrame([[int_protein_id, description, start, end]], columns=['uniprot_id', 'description', 'start', 'end'])])\n",
    "    return parsed_df\n",
    "\n",
    "def download_topological_domains(input_glyco_file, output_file, uniprot_id_column = \"Protein ID\"):\n",
    "    # get the unique uniprot ids from the input file\n",
    "    df = pd.read_csv(input_glyco_file)\n",
    "    id_list = df[uniprot_id_column].unique()\n",
    "    # create a new data frame\n",
    "    out_df = pd.DataFrame(columns=['uniprot_id', 'description', 'start', 'end'])\n",
    "    # for every uniprot_id in the data frame, parse the topological domains\n",
    "    for i in tqdm.tqdm(id_list):\n",
    "        parsed_df = parse_uniprot_topological_domains(i)\n",
    "        if parsed_df is not None:\n",
    "            out_df = pd.concat([out_df, parsed_df])\n",
    "    # write the output file\n",
    "    out_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb6defc5d2845378aa1f77d54e39761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features for A2RUG3\n",
      "No features for P0DN76\n"
     ]
    }
   ],
   "source": [
    "# download data for human cell lines\n",
    "input_file = \"data/raw_data/hek_hela_nglyco.csv\"\n",
    "output_file = \"data/topological_domains/human_topological_domains.csv\"\n",
    "download_topological_domains(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5dc20bf48734211954dc90e9ada48cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features for E9Q5E3\n",
      "No features for E9PYH1\n",
      "No features for D3Z3Y0\n",
      "No features for E9PW22\n",
      "No features for A2AC16\n",
      "No features for D6RFU9\n",
      "No features for D6RIL8\n",
      "No features for A0A0J9YUD5\n",
      "No features for A0A0G2JGP7\n",
      "No features for H3BJV9\n",
      "No features for B2RX70\n",
      "No features for A0A494BAA2\n",
      "No features for Q80X68\n",
      "No features for A0A0A6YXS5\n",
      "No features for S4R197\n"
     ]
    }
   ],
   "source": [
    "# download human for mouse\n",
    "input_file = \"data/raw_data/mouse_brain_nglyco.csv\"\n",
    "output_file = \"data/topological_domains/mouse_topological_domains.csv\"\n",
    "download_topological_domains(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8692fbe41c986e5b7f5784af7fd9b01be2e027249d3b6f00457e8e9a33ccb6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
